{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1006.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "19G0o8oSJl_9hcGGv9a1XwWQde7aRsVjj",
      "authorship_tag": "ABX9TyOfxA/PpX9M6rebQidMI1Kr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syunsuke1024/Portfolio-1-competitive-programming/blob/master/1006.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5sNNK8G3J3",
        "outputId": "aab22c5c-49fe-4227-cdb2-79c7ce7c539f"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.9.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.5.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.5)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.2.2)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrdcnksFHCWl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import optuna\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import RobustScaler, normalize\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
        "\n",
        "from IPython.display import display"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7D9fslHOk2"
      },
      "source": [
        "DEBUG = False\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/test.csv')\n",
        "submission = pd.read_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/sample_submission.csv')\n",
        "\n",
        "if DEBUG:\n",
        "    train = train[:80*100]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjpDr4FhHSQb"
      },
      "source": [
        "def add_features(df):\n",
        "    df['area'] = df['time_step'] * df['u_in']\n",
        "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
        "    \n",
        "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
        "\n",
        "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
        "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
        "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
        "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
        "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
        "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
        "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
        "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
        "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
        "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
        "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
        "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
        "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
        "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
        "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
        "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
        "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
        "    \n",
        "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
        "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
        "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
        "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
        "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
        "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
        "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
        "    df['cross']= df['u_in']*df['u_out']\n",
        "    df['cross2']= df['time_step']*df['u_out']\n",
        "    \n",
        "    df['R'] = df['R'].astype(str)\n",
        "    df['C'] = df['C'].astype(str)\n",
        "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
        "    df = pd.get_dummies(df)\n",
        "    return df\n",
        "\n",
        "train = add_features(train)\n",
        "test = add_features(test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szTzsfKZIZoa"
      },
      "source": [
        "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
        "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
        "test = test.drop(['id', 'breath_id'], axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fojx3H8gIg8S"
      },
      "source": [
        "RS = RobustScaler()\n",
        "train = RS.fit_transform(train)\n",
        "test = RS.transform(test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZHAAdPZIj19"
      },
      "source": [
        "train = train.reshape(-1, 80, train.shape[-1])\n",
        "test = test.reshape(-1, 80, train.shape[-1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a90Bac6PIpVY"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import tensorflow.keras.backend as K\n",
        "class WarmupExponentialDecay(Callback):\n",
        "    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n",
        "        self.num_passed_batchs = 0   #一个计数器\n",
        "        self.warmup_epochs=warmup_epochs  \n",
        "        self.lr=lr_base #learning_rate_base\n",
        "        self.lr_min=lr_min #最小的起始学习率,此代码尚未实现\n",
        "        self.decay=decay  #指数衰减率\n",
        "        self.steps_per_epoch=0 #也是一个计数器\n",
        "        \n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # params是模型自动传递给Callback的一些参数\n",
        "        if self.steps_per_epoch==0:\n",
        "            #防止跑验证集的时候呗更改了\n",
        "            if self.params['steps'] == None:\n",
        "                self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n",
        "            else:\n",
        "                self.steps_per_epoch = self.params['steps']\n",
        "        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n",
        "            K.set_value(self.model.optimizer.lr,\n",
        "                        self.lr*(self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr,\n",
        "                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n",
        "        self.num_passed_batchs += 1\n",
        "\n",
        "    def on_epoch_begin(self,epoch,logs=None):\n",
        "        #用来输出学习率的,可以删除\n",
        "        print(\"learning_rate:\",K.get_value(self.model.optimizer.lr))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPcccI2hI_uA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de282002-7352-4b5a-f0fb-ba6badfdd36b"
      },
      "source": [
        "EPOCH = 300\n",
        "BATCH_SIZE = 1024\n",
        "NUM_FOLDS = 10\n",
        "\n",
        "# detect and init the TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "\n",
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=3)\n",
        "    test_preds = []\n",
        "    train_preds = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
        "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
        "        if fold <= 3:\n",
        "          continue\n",
        "        else:\n",
        "            \n",
        "          X_train, X_valid = train[train_idx], train[test_idx]\n",
        "          y_train, y_valid = targets[train_idx], targets[test_idx]\n",
        "          model = keras.models.Sequential([\n",
        "              keras.layers.Input(shape=train.shape[-2:]),\n",
        "              keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n",
        "              keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n",
        "              keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n",
        "              keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "  #             keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "              keras.layers.Dense(128, activation='selu'),\n",
        "  #             keras.layers.Dropout(0.1),\n",
        "              keras.layers.Dense(1),\n",
        "          ])\n",
        "          model.compile(optimizer=\"adam\", loss=\"mae\")\n",
        "\n",
        "  #         scheduler = ExponentialDecay(1e-3, 40*((len(train)*0.8)/BATCH_SIZE), 1e-5)\n",
        "  #         lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "          lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
        "  #         lr = WarmupExponentialDecay(lr_base=1e-3, decay=1e-5, warmup_epochs=30)\n",
        "          es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n",
        "      \n",
        "          checkpoint_filepath = f\"/content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds{fold}.hdf5\"\n",
        "          sv = keras.callbacks.ModelCheckpoint(\n",
        "              checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "              save_weights_only=False, mode='auto', save_freq='epoch',\n",
        "              options=None\n",
        "          )\n",
        "\n",
        "          model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
        "          #model.save(f'Fold{fold+1} RNN Weights')\n",
        "          test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n",
        "          submission[\"pressure\"] = sum(test_preds)/1\n",
        "          submission.to_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/1006/test_003-'+str(fold)+\".csv\", index=False)\n",
        "          test_preds = []\n",
        "          train_preds.append(model.predict(train).squeeze().reshape(-1, 1).squeeze())\n",
        "          t = pd.read_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/train.csv')\n",
        "          t[\"pressure\"] = sum(train_preds)/1\n",
        "          t[\"pressure\"].to_csv('/content/drive/MyDrive/kaggle-paper2021-09-23/1006/train_003-'+str(fold)+\".csv\", index=False)\n",
        "          train_preds = []\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.22.252.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.22.252.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- > Fold 1 < ---------------\n",
            "--------------- > Fold 2 < ---------------\n",
            "--------------- > Fold 3 < ---------------\n",
            "--------------- > Fold 4 < ---------------\n",
            "--------------- > Fold 5 < ---------------\n",
            "Epoch 1/300\n",
            "67/67 [==============================] - 104s 1s/step - loss: 2.4565 - val_loss: 1.3938\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.39383, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 2/300\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.9065 - val_loss: 0.7103\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.39383 to 0.71031, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 3/300\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.6872 - val_loss: 0.6313\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.71031 to 0.63133, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 4/300\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.5886 - val_loss: 0.5626\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63133 to 0.56255, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 5/300\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.5262 - val_loss: 0.4714\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.56255 to 0.47139, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 6/300\n",
            "67/67 [==============================] - 43s 640ms/step - loss: 0.4850 - val_loss: 0.5582\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.47139\n",
            "Epoch 7/300\n",
            "67/67 [==============================] - 43s 639ms/step - loss: 0.4738 - val_loss: 0.4573\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.47139 to 0.45730, saving model to /content/drive/MyDrive/kaggle-paper2021-09-23/1006/003folds4.hdf5\n",
            "Epoch 8/300\n",
            "17/67 [======>.......................] - ETA: 31s - loss: 0.4339"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrQ0BBi4HK0W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}